{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "409d0715",
   "metadata": {},
   "source": [
    "# Process Data\n",
    "The processing consists of three steps:\n",
    "1. Remove unnecessary columns.\n",
    "2. Process data: fill missing ages, normalize ages and Pclass between 0 and 1, and encode Sex as 0 and 1.\n",
    "3. Shuffle and split data for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef69657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a335dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessData(data):\n",
    "    processed_data = data[[\"Pclass\", \"Sex\", \"Age\"]].copy() # keep only the necessary columns\n",
    "\n",
    "    processed_data['Age'] = processed_data['Age'].fillna(processed_data['Age'].median()) # Fill missing ages with the median\n",
    "    processed_data['Age'] = (processed_data['Age']) / 100 # Normalize age to [0, 1]\n",
    "    processed_data['Pclass'] = (processed_data['Pclass'] - 1) / 2 # Normalize passenger class to [0, 1]\n",
    "    processed_data['Sex'] = LabelEncoder().fit_transform(processed_data['Sex']) # Encode gender data to 0 and 1\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa87dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (891, 12) \n",
      "Processed shape: (891, 3)\n",
      "Original test shape: (418, 11) \n",
      "Processed test shape: (418, 3)\n",
      "Train data shape: (784, 3) (784,)\n",
      "Train test shape: (107, 3) (107,)\n"
     ]
    }
   ],
   "source": [
    "#  preprocess the data\n",
    "original = pd.read_csv(\"data/original.csv\")\n",
    "original_test = pd.read_csv(\"data/original_test.csv\")\n",
    "\n",
    "processed_data_labels = original['Survived']\n",
    "processed_data = ProcessData(original)\n",
    "processed_test_data = ProcessData(original_test)\n",
    "print(\"Original shape:\", original.shape, \"\\nProcessed shape:\", processed_data.shape)\n",
    "print(\"Original test shape:\", original_test.shape, \"\\nProcessed test shape:\", processed_test_data.shape)\n",
    "\n",
    "# save the processed data\n",
    "processed_data.to_csv(\"data/processed_data.csv\", index=False)\n",
    "processed_data_labels.to_csv(\"data/processed_data_labels.csv\", index=False)\n",
    "processed_test_data.to_csv(\"data/processed_test_data.csv\", index=False)\n",
    "\n",
    "# split data into training and testing sets\n",
    "train_data, train_test, train_data_labels, train_test_labels = train_test_split(processed_data, processed_data_labels, test_size=0.12, random_state=12, shuffle=True)\n",
    "print(\"Train data shape:\", train_data.shape, train_data_labels.shape)\n",
    "print(\"Train test shape:\", train_test.shape, train_test_labels.shape)\n",
    "\n",
    "# save data for training\n",
    "train_data.to_csv(\"data/train_data.csv\", index=False)\n",
    "train_data_labels.to_csv(\"data/train_data_labels.csv\", index=False)\n",
    "train_test.to_csv(\"data/train_test.csv\", index=False)\n",
    "train_test_labels.to_csv(\"data/train_test_labels.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
